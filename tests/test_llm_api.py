import unittest
from unittest.mock import patch, MagicMock
import os
from tools.llm_api import create_llm_client, query_llm

class TestLLMAPI(unittest.TestCase):
    def setUp(self):
        # Create a mock OpenAI client
        self.mock_client = MagicMock()
        self.mock_response = MagicMock()
        self.mock_choice = MagicMock()
        self.mock_message = MagicMock()
        
        # Set up the mock response structure
        self.mock_message.content = "Test response"
        self.mock_choice.message = self.mock_message
        self.mock_response.choices = [self.mock_choice]
        
        # Set up the mock client's chat.completions.create method
        self.mock_client.chat.completions.create.return_value = self.mock_response

    @patch('tools.llm_api.OpenAI')
    def test_create_llm_client(self, mock_openai):
        # Test client creation
        mock_openai.return_value = self.mock_client
        
        # Store original env var
        original_api_key = os.environ.get('OPENAI_API_KEY')
        
        try:
            # Set test API key
            os.environ['OPENAI_API_KEY'] = 'test-api-key'
            
            client = create_llm_client()
            
            # Verify OpenAI was called with correct parameters
            mock_openai.assert_called_once_with(
                api_key='test-api-key'
            )
            
            self.assertEqual(client, self.mock_client)
        finally:
            # Restore original env var
            if original_api_key:
                os.environ['OPENAI_API_KEY'] = original_api_key
            else:
                del os.environ['OPENAI_API_KEY']

    @patch('tools.llm_api.create_llm_client')
    def test_query_llm_success(self, mock_create_client):
        # Set up mock
        mock_create_client.return_value = self.mock_client
        
        # Test query with default parameters
        response = query_llm("Test prompt")
        
        # Verify response
        self.assertEqual(response, "Test response")
        
        # Verify client was called correctly
        self.mock_client.chat.completions.create.assert_called_once_with(
            model="gpt-4o",
            messages=[{"role": "user", "content": "Test prompt"}],
            temperature=0.7
        )

    @patch('tools.llm_api.create_llm_client')
    def test_query_llm_with_custom_model(self, mock_create_client):
        # Set up mock
        mock_create_client.return_value = self.mock_client
        
        # Test query with custom model
        response = query_llm("Test prompt", model="custom-model")
        
        # Verify response
        self.assertEqual(response, "Test response")
        
        # Verify client was called with custom model
        self.mock_client.chat.completions.create.assert_called_once_with(
            model="custom-model",
            messages=[{"role": "user", "content": "Test prompt"}],
            temperature=0.7
        )

    @patch('tools.llm_api.create_llm_client')
    def test_query_llm_with_existing_client(self, mock_create_client):
        # Test query with provided client
        response = query_llm("Test prompt", client=self.mock_client)
        
        # Verify response
        self.assertEqual(response, "Test response")
        
        # Verify create_client was not called
        mock_create_client.assert_not_called()

    @patch('tools.llm_api.create_llm_client')
    def test_query_llm_error(self, mock_create_client):
        # Set up mock to raise an exception
        self.mock_client.chat.completions.create.side_effect = Exception("Test error")
        mock_create_client.return_value = self.mock_client
        
        # Test query with error
        response = query_llm("Test prompt")
        
        # Verify error handling
        self.assertIsNone(response)

if __name__ == '__main__':
    unittest.main()
